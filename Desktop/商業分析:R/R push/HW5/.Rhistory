# 還要再減一，因為我們一開始就先抓了前20筆
page <- (200/20)-1
#抓到的最後一篇文章id
end <- resdata$id[length(resdata$id)]
#寫一個loop，重複做page次
for(i in 1:page){
# 從「目前抓到的最後一篇文章id」往前抓20篇
url <- paste0(mainurl,"&before=",end)
# 測試時可以把url印出來檢查有沒有抓對
print(url)
# 把抓到存入暫存的tmpres，這只是暫存
tmpres <- fromJSON(content(GET(url), "text"))
# 從tmpres裡更新「最後一篇文章的id」
end <- tmpres$id[length(tmpres$id)]
# 然後把我們新抓到的tmpres和之前已經有的resdata合併
resdata <- bind_rows(resdata[,c(1:12)],tmpres[,c(1:12)])
}
#省記憶體
rm(tmpres)
#查看前幾筆
head(resdata)
count <-table(cc[resdata[,2]])
newd = data.frame(count)
head(newd[order(newd$Freq,decreasing = TRUE),],20)
newdd = newd[order(newd$Freq,decreasing = TRUE),]
wordcloud2(newdd)
count <-table(cc[resdata[,2]])
#查看前幾筆
head(resdata)
count <-table(cc[resdata[,2]])
# Analysis
#segment_not <- c("","","","") #不想拆分開的字
#new_user_word(cc, segment_not) #增加字定義的辭彙
count <-table(cc[resdata[,2]])
cc<-worker()
count <-table(cc[resdata[,2]])
newd = data.frame(count)
head(newd[order(newd$Freq,decreasing = TRUE),],20)
newdd = newd[order(newd$Freq,decreasing = TRUE),]
wordcloud2(newdd)
word <- cc[resdata[,2]]
newd = data.frame(table(word))
newd %>%
filter(!str_detect(word, "[a-zA-Z0-9]+")) %>%  #去掉english and number
filter(nchar(as.character(word)) > 1) %>% #一個字的去掉
filter( Freq > 2) ->temp #可留下頻率>某數字
wordcloud2(temp, shape='diamond')
newd %>%
filter(!str_detect(word, "[a-zA-Z0-9]+")) %>%  #去掉english and number
filter(nchar(as.character(word)) > 1) %>% #一個字的去掉
filter( Freq > 1) ->temp #可留下頻率>某數字
newd %>%
filter(!str_detect(word, "[a-zA-Z0-9]+")) %>%  #去掉english and number
filter(nchar(as.character(word)) > 1) %>% #一個字的去掉
filter( Freq > 1) ->temp #可留下頻率>某數字
wordcloud2(temp, shape='diamond')
library(httr)
library(jsonlite)
library(tidyverse)
options(stringsAsFactors = FALSE)
options(encoding = "UTF-8")
dcardurl <- "https://www.dcard.tw/_api/forums/"
board <- 'makeup'
#把url跟看板融合成一個網址，將抓的順序設定成熱門排序，所以用true
mainurl <- paste0(dcardurl,board,'/posts?popular=true')
# 抽出json，把他存入resdata這個data.frame裡面
resdata <- fromJSON(content(GET(mainurl), "text"))
#先查看前兩個Column
head(resdata[,c(1,2)])
#假設要抓200篇文章
n <- 200
# 因為不改limit值，所以他預設會每次抓20篇回來，我們把要抓的文章/20便是我們要抓的次數
# 還要再減一，因為我們一開始就先抓了前20筆
page <- (200/20)-1
#抓到的最後一篇文章id
end <- resdata$id[length(resdata$id)]
#寫一個loop，重複做page次
for(i in 1:page){
# 從「目前抓到的最後一篇文章id」往前抓20篇
url <- paste0(mainurl,"&before=",end)
# 測試時可以把url印出來檢查有沒有抓對
print(url)
# 把抓到存入暫存的tmpres，這只是暫存
tmpres <- fromJSON(content(GET(url), "text"))
# 從tmpres裡更新「最後一篇文章的id」
end <- tmpres$id[length(tmpres$id)]
# 然後把我們新抓到的tmpres和之前已經有的resdata合併
resdata <- bind_rows(resdata[,c(1:12)],tmpres[,c(1:12)])
}
#省記憶體
rm(tmpres)
#查看前幾筆
head(resdata)
cc<-worker()
count <-table(cc[resdata[,2]])
newd = data.frame(count)
head(newd[order(newd$Freq,decreasing = TRUE),],20)
newdd = newd[order(newd$Freq,decreasing = TRUE),]
wordcloud2(newdd)
word <- cc[resdata[,2]]
newd = data.frame(table(word))
newd %>%
filter(!str_detect(word, "[a-zA-Z0-9]+")) %>%  #去掉english and number
filter(nchar(as.character(word)) > 1) %>% #一個字的去掉
filter( Freq > 1) ->temp #可留下頻率>某數字
wordcloud2(temp)
library(devtools)
library("jiebaR")
library(tm)
library(tmcn)
library('wordcloud2')
data <- read.csv("women_clothes.csv")
Recommend <- data[data$Recommended.IND == 1,]
Unrecommend <- data[data$Recommended.IND == 0,]
Recommend_words <- Recommend$Review.Text
Unrecommend_words <- Unrecommend$Review.Text
cc<-worker()
cc[Recommend_words]
count <-freq(cc[Recommend_words])
count
str(count)
newd = data.frame(count) #定義成dataframe
head(newd[order(newd$freq,decreasing = TRUE),],20) #按次數排序
newdd = newd[order(newd$freq,decreasing = TRUE),] #存成新資料集
wordcloud2(newdd)
library(tidyverse)
newd%>%
filter(freq > 3) %>%
mutate(word = reorder(char, freq)) %>% #reorder char by freq
ggplot(aes(word,freq))+
theme(text=element_text(family="PMingLiU", size=14))+
geom_col() +
xlab(NULL) +
ylab("Frequency")+
coord_flip()
wordcloud2(newdd)
tdm <- TermDocumentMatrix(newdd, control =list(wordLengths = c(2, Inf)))
tdm <- TermDocumentMatrix(newd, control =list(wordLengths = c(2, Inf)))
x <- VectorSource(choudf) #把歌詞存進向量
x <- VectorSource(choudf) #把歌詞存進向量
x <- Corpus(x) #collection of all text files #把歌詞存成文檔
newd %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
newd %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
newd%>%
filter(freq > 3) %>%
mutate(word = reorder(char, freq)) %>% #reorder char by freq
ggplot(aes(word,freq))+
theme(text=element_text(family="PMingLiU", size=14))+
geom_col() +
xlab(NULL) +
ylab("Frequency")+
coord_flip()
newd
tdm <- TermDocumentMatrix(cc, control =list(wordLengths = c(2, Inf)))
tdm <- TermDocumentMatrix(cc, control =list(wordLengths = c(2, Inf)))
x <- VectorSource(Recommend_words)
x <- Corpus(x)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
tdm #Term Document Matrix
inspect(tdm) #各文件字的出現次數
x <- tm_map(x, function(word) {
gsub("[A-Za-z0-9]", "", word)
}) #去除english and number
x <- VectorSource(Recommend_words)
x <- Corpus(x)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
tdm #Term Document Matrix
inspect(tdm) #各文件字的出現次數
x<-tm_map(x,stripWhitespace) #space
x<-tm_map(x,removeNumbers) #numbers
x<-tm_map(x,removePunctuation) #punctuation
x<-tm_map(x,stripWhitespace) #space
inspect(tdm) #各文件字的出現次數
myStopWords <- c(stopwords())#remove some words，stopwordsCN是既定的字典
x <- tm_map(x, removeWords, myStopWords)
head(myStopWords)
x <- VectorSource(Recommend_words)
x <- VCorpus(x)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
tdm #Term Document Matrix
inspect(tdm) #各文件字的出現次數
myStopWords <- c(stopwords())#remove some words，stopwordsCN是既定的字典
x <- tm_map(x, removeWords, myStopWords)
head(myStopWords)
dtm<-DocumentTermMatrix(x)
inspect(dtm)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf))) #挑兩個詞以上的
inspect(tdm)
m1 <- as.matrix(tdm) #轉Matrix
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v) #count freq
head(d)
wordcloud2(d,size=0.5)
d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
d
new_d <- d[d$freq > 500]
new_d <- d[freq > 500]
new_d <- d[freq > 500]
new_d <- d[freq > 500,]
new_d <- d[d$freq > 500,]
new_d <- d[d$freq > 500,]
head(new_d)
wordcloud2(new_d,size=0.5)
new_d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d <- d[d$freq > 1000,]
extract_d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d <- d[d$freq > 3000,]
extract_d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d <- d[d$freq > 2000,]
extract_d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
inspect(tdm)
y <- VectorSource(Unrecommend_words)
y <- VCorpus(y)
dtm <- TermDocumentMatrix(y, control =list(wordLengths = c(2, Inf)))
y <- dm_map(y, removeWords, myStopWords)
y <- tm_map(y, removeWords, myStopWords)
tdm2 <- TermDocumentMatrix(y, control =list(wordLengths = c(2, Inf)))
dtm<-DocumentTermMatrix(x)
inspect(dtm)
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v), freq = v) #count freq
new_d2 <- d2[d2$freq > 500,]
head(new_d2)
#擷取心得欄
Recommend_words <- Recommend$Review.Text
Unrecommend_words <- Unrecommend$Review.Text
x <- VectorSource(Recommend_words)
x <- VCorpus(x)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
y <- VectorSource(Unrecommend_words)
y <- VCorpus(y)
tdm2 <- TermDocumentMatrix(y, control =list(wordLengths = c(2, Inf)))
myStopWords <- c(stopwords()) #remove some words
x <- tm_map(x, removeWords, myStopWords)
y <- tm_map(y, removeWords, myStopWords)
head(myStopWords)
m1 <- as.matrix(tdm) #轉Matrix
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v) #count freq
new_d <- d[d$freq > 500,]
head(new_d)
wordcloud2(new_d,size=0.5)
extract_d <- d[d$freq > 2000,]
extract_d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v), freq = v) #count freq
new_d2 <- d2[d2$freq > 500,]
head(new_d2)
y <- tm_map(y, removeWords, myStopWords)
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v), freq = v) #count freq
new_d2 <- d2[d2$freq > 500,]
head(new_d2)
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v2), freq = v2) #count freq
new_d2 <- d2[d2$freq > 500,]
head(new_d2)
y <- VectorSource(Unrecommend_words)
y <- VCorpus(y)
tdm2 <- TermDocumentMatrix(y, control =list(wordLengths = c(2, Inf)))
y <- tm_map(y, removeWords, myStopWords)
y
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v2), freq = v2) #count freq
new_d2 <- d2[d2$freq > 500,]
head(new_d2)
x <- VectorSource(Recommend_words)
x <- VCorpus(x)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
myStopWords <- c(stopwords()) #remove some words
x <- tm_map(x, removeWords, myStopWords)
y <- tm_map(y, removeWords, myStopWords)
head(myStopWords)
m1 <- as.matrix(tdm) #轉Matrix
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v) #count freq
new_d <- d[d$freq > 500,]
head(new_d)
wordcloud2(new_d,size=0.5)
data <- read.csv("women_clothes.csv")
#將資料分成兩組
Recommend <- data[data$Recommended.IND == 1,]
Unrecommend <- data[data$Recommended.IND == 0,]
#擷取心得欄
Recommend_words <- Recommend$Review.Text
Unrecommend_words <- Unrecommend$Review.Text
x <- VectorSource(Recommend_words)
x <- VCorpus(x)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
myStopWords <- c(stopwords()) #remove some words
x <- tm_map(x, removeWords, myStopWords)
head(myStopWords)
m1 <- as.matrix(tdm) #轉Matrix
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v) #count freq
new_d <- d[d$freq > 500,]
head(new_d)
wordcloud2(new_d,size=0.5)
myStopWords <- c(stopwords()) #remove some words
x <- tm_map(x, removeWords, myStopWords)
m1 <- as.matrix(x) #轉Matrix
x <- VectorSource(Recommend_words)
x <- VCorpus(x)
myStopWords <- c(stopwords()) #remove some words
x <- tm_map(x, removeWords, myStopWords)
head(myStopWords)
tdm <- TermDocumentMatrix(x, control =list(wordLengths = c(2, Inf)))
m1 <- as.matrix(tdm) #轉Matrix
v <- sort(rowSums(m1), decreasing = TRUE)
d <- data.frame(word = names(v), freq = v) #count freq
new_d <- d[d$freq > 500,]
head(new_d)
wordcloud2(new_d,size=0.5)
extract_d <- d[d$freq > 2000,]
extract_d %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
wordcloud2(new_d,size=0.5)
y <- VectorSource(Unrecommend_words)
y <- VCorpus(y)
myStopWords <- c(stopwords()) #remove some words
y <- tm_map(y, removeWords, myStopWords)
head(myStopWords)
tdm2 <- TermDocumentMatrix(y, control =list(wordLengths = c(2, Inf)))
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v2), freq = v2) #count freq
new_d2 <- d2[d2$freq > 500,]
head(new_d2)
wordcloud2(new_d2,size=0.5)
extract_d2 <- d2[d2$freq > 2000,]
new_d2 <- d2[d2$freq > 300,]
head(new_d2)
wordcloud2(new_d2,size=0.5)
new_d2 <- d2[d2$freq > 200,]
y
View(y)
y <- VectorSource(Unrecommend_words)
y <- VCorpus(y)
myStopWords <- c(stopwords()) #remove some words
y <- tm_map(y, removeWords, myStopWords)
head(myStopWords)
tdm2 <- TermDocumentMatrix(y, control =list(wordLengths = c(2, Inf)))
m2 <- as.matrix(tdm2) #轉Matrix
v2 <- sort(rowSums(m2), decreasing = TRUE)
d2 <- data.frame(word = names(v2), freq = v2) #count freq
new_d2 <- d2[d2$freq > 200,]
head(new_d2)
wordcloud2(new_d2,size=0.5)
extract_d2 <- d2[d2$freq > 2000,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
wordcloud2(new_d2,size=0.5)
new_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 <- d2[d2$freq > 500,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 <- d2[d2$freq > 600,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 <- d2[d2$freq > 400,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 <- d2[d2$freq > 350,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 <- d2[d2$freq > 300,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
extract_d2 <- d2[d2$freq > 500,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
new_d2 <- d2[d2$freq > 100,]
head(new_d2)
wordcloud2(new_d2,size=0.5)
new_d2 <- d2[d2$freq > 200,]
head(new_d2)
View(tdm)
wordcloud2(new_d2,size=0.5)
wordcloud2(new_d2,size=0.5)
extract_d2 <- d2[d2$freq > 500,]
extract_d2 %>%
filter(freq > 6) %>%
mutate(word = reorder(word, freq)) %>%
ggplot(aes(word,freq))+
theme(text=element_text(family="微軟正黑體", size=14))+
geom_col() +
xlab(NULL) +
coord_flip()
